{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"deepspeech-colab.ipynb","provenance":[{"file_id":"10DjkY6bimQfvpjf2UNx85mJBlHLjNe40","timestamp":1593344529408}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"mfORIS4dxb0U","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593344687904,"user_tz":-300,"elapsed":10315,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"af3952f0-aef1-461f-8522-56691c3045a7"},"source":["import tensorflow as tf  # test if GPU is there\n","tf.test.gpu_device_name()"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"yG5MScDK80zT","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OGQ1SCoL1Bh2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":937},"executionInfo":{"status":"ok","timestamp":1593344783584,"user_tz":-300,"elapsed":80808,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"abc58da1-21b6-43bd-aea5-ef2428a6a049"},"source":["# clone the repo\n","\n","!wget -O git-lfs.tar.gz https://github.com/git-lfs/git-lfs/releases/download/v2.4.2/git-lfs-linux-amd64-2.4.2.tar.gz\n","!tar -xvzf git-lfs.tar.gz\n","!./git-lfs-2.4.2/install.sh\n","!git lfs clone https://github.com/mozilla/deepspeech\n","%cd deepspeech\n","!git checkout -f tags/v0.7.3\n","%cd .."],"execution_count":2,"outputs":[{"output_type":"stream","text":["--2020-06-28 11:45:05--  https://github.com/git-lfs/git-lfs/releases/download/v2.4.2/git-lfs-linux-amd64-2.4.2.tar.gz\n","Resolving github.com (github.com)... 140.82.118.3\n","Connecting to github.com (github.com)|140.82.118.3|:443... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://github-production-release-asset-2e65be.s3.amazonaws.com/13021798/3b2fb1fc-62ae-11e8-9816-cb226f383a73?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200628%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200628T114505Z&X-Amz-Expires=300&X-Amz-Signature=33461f5457228bb8a4a4e4f90ddcbdae5dce07b5e811d4d175aa80046d16b844&X-Amz-SignedHeaders=host&actor_id=0&repo_id=13021798&response-content-disposition=attachment%3B%20filename%3Dgit-lfs-linux-amd64-2.4.2.tar.gz&response-content-type=application%2Foctet-stream [following]\n","--2020-06-28 11:45:05--  https://github-production-release-asset-2e65be.s3.amazonaws.com/13021798/3b2fb1fc-62ae-11e8-9816-cb226f383a73?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20200628%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200628T114505Z&X-Amz-Expires=300&X-Amz-Signature=33461f5457228bb8a4a4e4f90ddcbdae5dce07b5e811d4d175aa80046d16b844&X-Amz-SignedHeaders=host&actor_id=0&repo_id=13021798&response-content-disposition=attachment%3B%20filename%3Dgit-lfs-linux-amd64-2.4.2.tar.gz&response-content-type=application%2Foctet-stream\n","Resolving github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)... 52.217.11.140\n","Connecting to github-production-release-asset-2e65be.s3.amazonaws.com (github-production-release-asset-2e65be.s3.amazonaws.com)|52.217.11.140|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2930483 (2.8M) [application/octet-stream]\n","Saving to: ‘git-lfs.tar.gz’\n","\n","git-lfs.tar.gz      100%[===================>]   2.79M  4.43MB/s    in 0.6s    \n","\n","2020-06-28 11:45:06 (4.43 MB/s) - ‘git-lfs.tar.gz’ saved [2930483/2930483]\n","\n","git-lfs-2.4.2/\n","git-lfs-2.4.2/git-lfs\n","git-lfs-2.4.2/CHANGELOG.md\n","git-lfs-2.4.2/install.sh\n","git-lfs-2.4.2/README.md\n","Error: Failed to call git rev-parse --git-dir --show-toplevel: \"fatal: not a git repository (or any of the parent directories): .git\\n\"\n","Git LFS initialized.\n","WARNING: 'git lfs clone' is deprecated and will not be updated\n","          with new flags from 'git clone'\n","\n","'git clone' has been updated in upstream Git to have comparable\n","speeds to 'git lfs clone'.\n","Cloning into 'deepspeech'...\n","remote: Enumerating objects: 70, done.\u001b[K\n","remote: Counting objects: 100% (70/70), done.\u001b[K\n","remote: Compressing objects: 100% (51/51), done.\u001b[K\n","remote: Total 19257 (delta 20), reused 32 (delta 14), pack-reused 19187\u001b[K\n","Receiving objects: 100% (19257/19257), 47.92 MiB | 16.33 MiB/s, done.\n","Resolving deltas: 100% (13134/13134), done.\n","/content/deepspeech\n","Note: checking out 'tags/v0.7.3'.\n","\n","You are in 'detached HEAD' state. You can look around, make experimental\n","changes and commit them, and you can discard any commits you make in this\n","state without impacting any branches by performing another checkout.\n","\n","If you want to create a new branch to retain commits you create, you may\n","do so (now or later) by using -b with the checkout command again. Example:\n","\n","  git checkout -b <new-branch-name>\n","\n","HEAD is now at 88584941 Merge pull request #3036 from lissyx/doc-fix\n","/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"o1f5x3BuEkB6","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593283075458,"user_tz":-300,"elapsed":4135,"user":{"displayName":"Raja Asim","photoUrl":"","userId":"17826990570129583802"}},"outputId":"a2a98708-c89a-4dab-b023-52148d9aa6bc"},"source":["!ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["deepspeech  deepspeech-colab.ipynb  new_checkpoints  training_data\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bY5GPoM2Jjgz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593344835213,"user_tz":-300,"elapsed":127622,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"5b071c2c-423c-4441-90ae-328886e5c10b"},"source":["!pip3 install -r deepspeech/requirements_transcribe.txt\n","!pip3 install -r deepspeech/requirements_tests.txt\n","!pip3 install -r deepspeech/requirements_eval_tflite.txt\n","!pip3 install deepspeech-gpu\n","\n","%cd deepspeech\n","\n","!pip3 install -e .  # install reqs if missed any\n","%cd .."],"execution_count":3,"outputs":[{"output_type":"stream","text":["Collecting webrtcvad\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/89/34/e2de2d97f3288512b9ea56f92e7452f8207eb5a0096500badf9dfd48f5e6/webrtcvad-2.0.10.tar.gz (66kB)\n","\r\u001b[K     |█████                           | 10kB 16.8MB/s eta 0:00:01\r\u001b[K     |██████████                      | 20kB 4.6MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 30kB 6.0MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 40kB 6.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 51kB 5.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 61kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 4.0MB/s \n","\u001b[?25hBuilding wheels for collected packages: webrtcvad\n","  Building wheel for webrtcvad (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for webrtcvad: filename=webrtcvad-2.0.10-cp36-cp36m-linux_x86_64.whl size=71383 sha256=b4fa46a41b440b74ae727a59af172ad27818caf99661ebe45231a4298b4eb791\n","  Stored in directory: /root/.cache/pip/wheels/44/2a/18/bd1aec41cac7c3051fe95d92a6ed446122ea31dc713c432fa1\n","Successfully built webrtcvad\n","Installing collected packages: webrtcvad\n","Successfully installed webrtcvad-2.0.10\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.6/dist-packages (from -r deepspeech/requirements_tests.txt (line 1)) (0.9.0)\n","Collecting argparse\n","  Downloading https://files.pythonhosted.org/packages/f2/94/3af39d34be01a24a6e65433d19e107099374224905f1e0cc6bbe1fd22a2f/argparse-1.4.0-py2.py3-none-any.whl\n","Collecting semver\n","  Downloading https://files.pythonhosted.org/packages/94/19/275d10576ad1b19b801efa478182d7352d244a40164162334010e3a948d5/semver-2.10.2-py2.py3-none-any.whl\n","Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from absl-py->-r deepspeech/requirements_tests.txt (line 1)) (1.12.0)\n","Installing collected packages: argparse, semver\n","Successfully installed argparse-1.4.0 semver-2.10.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["argparse"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Requirement already satisfied: absl-py==0.9.0 in /usr/local/lib/python3.6/dist-packages (from -r deepspeech/requirements_eval_tflite.txt (line 1)) (0.9.0)\n","Collecting attrdict==2.0.1\n","  Downloading https://files.pythonhosted.org/packages/ef/97/28fe7e68bc7adfce67d4339756e85e9fcf3c6fd7f0c0781695352b70472c/attrdict-2.0.1-py2.py3-none-any.whl\n","Collecting deepspeech\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/17/3694ad9f691b7d5f558c48cdc7a1b0c283ecfc22b31d9a8f5ffefb2c307a/deepspeech-0.7.4-cp36-cp36m-manylinux1_x86_64.whl (9.7MB)\n","\u001b[K     |████████████████████████████████| 9.7MB 7.2MB/s \n","\u001b[?25hCollecting numpy==1.16.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/74/54c5f9bb9bd4dae27a61ec1b39076a39d359b3fb7ba15da79ef23858a9d8/numpy-1.16.0-cp36-cp36m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 200kB/s \n","\u001b[?25hCollecting progressbar2==3.47.0\n","  Downloading https://files.pythonhosted.org/packages/16/68/adc395e0a3c86571081c8a2e2daaa5b58270f6854276a089a0e9b5fa2c33/progressbar2-3.47.0-py2.py3-none-any.whl\n","Collecting python-utils==2.3.0\n","  Downloading https://files.pythonhosted.org/packages/eb/a0/19119d8b7c05be49baf6c593f11c432d571b70d805f2fe94c0585e55e4c8/python_utils-2.3.0-py2.py3-none-any.whl\n","Collecting six==1.13.0\n","  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\n","Collecting pandas==0.25.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/3f/f6a428599e0d4497e1595030965b5ba455fd8ade6e977e3c819973c4b41d/pandas-0.25.3-cp36-cp36m-manylinux1_x86_64.whl (10.4MB)\n","\u001b[K     |████████████████████████████████| 10.4MB 42.4MB/s \n","\u001b[?25hRequirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->-r deepspeech/requirements_eval_tflite.txt (line 8)) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas==0.25.3->-r deepspeech/requirements_eval_tflite.txt (line 8)) (2.8.1)\n","\u001b[31mERROR: umap-learn 0.4.4 has requirement numpy>=1.17, but you'll have numpy 1.16.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement pandas~=1.0.0; python_version >= \"3.0\", but you'll have pandas 0.25.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.13.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n","\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n","Installing collected packages: six, attrdict, numpy, deepspeech, python-utils, progressbar2, pandas\n","  Found existing installation: six 1.12.0\n","    Uninstalling six-1.12.0:\n","      Successfully uninstalled six-1.12.0\n","  Found existing installation: numpy 1.18.5\n","    Uninstalling numpy-1.18.5:\n","      Successfully uninstalled numpy-1.18.5\n","  Found existing installation: python-utils 2.4.0\n","    Uninstalling python-utils-2.4.0:\n","      Successfully uninstalled python-utils-2.4.0\n","  Found existing installation: progressbar2 3.38.0\n","    Uninstalling progressbar2-3.38.0:\n","      Successfully uninstalled progressbar2-3.38.0\n","  Found existing installation: pandas 1.0.5\n","    Uninstalling pandas-1.0.5:\n","      Successfully uninstalled pandas-1.0.5\n","Successfully installed attrdict-2.0.1 deepspeech-0.7.4 numpy-1.16.0 pandas-0.25.3 progressbar2-3.47.0 python-utils-2.3.0 six-1.13.0\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","pandas","six"]}}},"metadata":{"tags":[]}},{"output_type":"stream","text":["Collecting deepspeech-gpu\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/29/39/a29a01ebd6700807f654acdc05db844dd0a78f46405acc2ff1295db4f27b/deepspeech_gpu-0.7.4-cp36-cp36m-manylinux1_x86_64.whl (19.2MB)\n","\u001b[K     |████████████████████████████████| 19.2MB 1.3MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from deepspeech-gpu) (1.16.0)\n","Installing collected packages: deepspeech-gpu\n","Successfully installed deepspeech-gpu-0.7.4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9mP-5NO0D4xM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":974},"executionInfo":{"status":"ok","timestamp":1593347041506,"user_tz":-300,"elapsed":22168,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"f200d74a-fae7-48d9-9af5-a8d6f56b7e1c"},"source":["# download and extract training data\n","!wget https://www.dropbox.com/sh/7wp15mwmuv6exdj/AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0\n","!mv 'AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0' data.tar\n","!unzip data.tar\n","!ls\n","!mkdir training_data\n","!cp -r {audio_chunks,train.csv,test.csv,val.csv} training_data  # copy files at relevant path\n","\n","!cp -r training_data deepspeech\n","\n","\n","\n","# download and extract checkpoints\n","!rm -r deepspeech/new_checkpoints\n","!wget https://www.dropbox.com/sh/i76w40hmb1m5jpi/AAC_eUJXRutNnrNaGHWUINnYa?dl=0\n","!mv 'AAC_eUJXRutNnrNaGHWUINnYa?dl=0' checkpoints.tar\n","!mkdir new_checkpoints/\n","!unzip checkpoints.tar\n","!cp {best_dev-732522.data-00000-of-00001,best_dev-732522.index,best_dev-732522.meta,best_dev_checkpoint} new_checkpoints\n","\n","!cp -r new_checkpoints deepspeech\n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["--2020-06-28 12:23:40--  https://www.dropbox.com/sh/7wp15mwmuv6exdj/AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0\n","Resolving www.dropbox.com (www.dropbox.com)... 162.125.67.1, 2620:100:6023:1::a27d:4301\n","Connecting to www.dropbox.com (www.dropbox.com)|162.125.67.1|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: /sh/raw/7wp15mwmuv6exdj/AAAb7LJE0jBGyJ0titPZ1jDZa [following]\n","--2020-06-28 12:23:41--  https://www.dropbox.com/sh/raw/7wp15mwmuv6exdj/AAAb7LJE0jBGyJ0titPZ1jDZa\n","Reusing existing connection to www.dropbox.com:443.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://uc4bb057389fd0159593c96c851d.dl.dropboxusercontent.com/zip_download_get/Ad7xqfrWH-Jd38rbwB3tGzNaRIrEAvIVY2PX90vpCkrJE1AocmT4ZatseC87dDbx-VKtw3USvZJrqh9ALhqfmPiUF60KLD4TT4RwkxoQxoW6mg [following]\n","--2020-06-28 12:23:41--  https://uc4bb057389fd0159593c96c851d.dl.dropboxusercontent.com/zip_download_get/Ad7xqfrWH-Jd38rbwB3tGzNaRIrEAvIVY2PX90vpCkrJE1AocmT4ZatseC87dDbx-VKtw3USvZJrqh9ALhqfmPiUF60KLD4TT4RwkxoQxoW6mg\n","Resolving uc4bb057389fd0159593c96c851d.dl.dropboxusercontent.com (uc4bb057389fd0159593c96c851d.dl.dropboxusercontent.com)... 162.125.67.15, 2620:100:6023:15::a27d:430f\n","Connecting to uc4bb057389fd0159593c96c851d.dl.dropboxusercontent.com (uc4bb057389fd0159593c96c851d.dl.dropboxusercontent.com)|162.125.67.15|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1942970 (1.9M) [application/zip]\n","Saving to: ‘AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0’\n","\n","AAAb7LJE0jBGyJ0titP 100%[===================>]   1.85M  4.06MB/s    in 0.5s    \n","\n","2020-06-28 12:23:43 (4.06 MB/s) - ‘AAAb7LJE0jBGyJ0titPZ1jDZa?dl=0’ saved [1942970/1942970]\n","\n","Archive:  data.tar\n","warning:  stripped absolute path spec from /\n","mapname:  conversion of  failed\n"," extracting: val.csv                 \n"," extracting: test.csv                \n"," extracting: train.csv               \n","   creating: audio_chunks/\n"," extracting: sample_data.csv         \n"," extracting: audio_chunks/185.wav    \n"," extracting: audio_chunks/179.wav    \n"," extracting: audio_chunks/181.wav    \n"," extracting: audio_chunks/178.wav    \n"," extracting: audio_chunks/184.wav    \n"," extracting: audio_chunks/177.wav    \n"," extracting: audio_chunks/175.wav    \n"," extracting: audio_chunks/182.wav    \n"," extracting: audio_chunks/180.wav    \n"," extracting: audio_chunks/183.wav    \n"," extracting: audio_chunks/176.wav    \n"," extracting: audio_chunks/174.wav    \n","alphabet.txt\t\t\t     checkpoints.tar  sample_data.csv\n","audio_chunks\t\t\t     data.tar\t      test.csv\n","best_dev-732522.data-00000-of-00001  deepspeech       train.csv\n","best_dev-732522.index\t\t     git-lfs-2.4.2    training_data\n","best_dev-732522.meta\t\t     git-lfs.tar.gz   val.csv\n","best_dev_checkpoint\t\t     new_checkpoints\n","checkpoint\t\t\t     sample_data\n","mkdir: cannot create directory ‘training_data’: File exists\n"],"name":"stdout"},{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic":{"type":"string"},"text/plain":["\"\\n# download and extract checkpoints\\n!rm -r deepspeech/new_checkpoints\\n!wget https://www.dropbox.com/sh/i76w40hmb1m5jpi/AAC_eUJXRutNnrNaGHWUINnYa?dl=0\\n!mv 'AAC_eUJXRutNnrNaGHWUINnYa?dl=0' checkpoints.tar\\n!mkdir new_checkpoints/\\n!unzip checkpoints.tar\\n!cp {best_dev-732522.data-00000-of-00001,best_dev-732522.index,best_dev-732522.meta,best_dev_checkpoint} new_checkpoints\\n\\n!cp -r new_checkpoints deepspeech\\n\""]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"id":"VN6hsWS-w6WU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":662},"executionInfo":{"status":"ok","timestamp":1593345116284,"user_tz":-300,"elapsed":377979,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"89bff45d-b077-4e23-b649-5cc121d71f18"},"source":["!pip3 uninstall tensorflow -y\n","!pip3 install tensorflow-gpu==1.15.2"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Uninstalling tensorflow-1.15.2:\n","  Successfully uninstalled tensorflow-1.15.2\n","Collecting tensorflow-gpu==1.15.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/ca/58e40e5077fa2a92004f398d705a288e958434f123938f4ce75ffe25b64b/tensorflow_gpu-1.15.2-cp36-cp36m-manylinux2010_x86_64.whl (411.0MB)\n","\u001b[K     |████████████████████████████████| 411.0MB 43kB/s \n","\u001b[?25hRequirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.34.2)\n","Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.2)\n","Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.8.1)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.16.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.9.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.13.0)\n","Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.0.8)\n","Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.2)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.1.0)\n","Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (0.2.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.2.1)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.12.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.30.0)\n","Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (3.10.0)\n","Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.1)\n","Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15.2) (1.15.0)\n","Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15.2) (2.10.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15.2) (47.3.1)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.2.2)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.0.1)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (1.6.1)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15.2) (3.1.0)\n","Installing collected packages: tensorflow-gpu\n","Successfully installed tensorflow-gpu-1.15.2\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["tensorflow"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"79uMqWtS8aMj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1593345119181,"user_tz":-300,"elapsed":377292,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"23f13707-7bd3-4b10-eb14-83944555462b"},"source":["%cd deepspeech   # to save the fine tuned model\n","!mkdir fine_tuned_model"],"execution_count":7,"outputs":[{"output_type":"stream","text":["/content/deepspeech\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zBWCgLfAqGm2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593348879815,"user_tz":-300,"elapsed":1822546,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"be36d02e-601a-4c28-bab2-69b6a2c9095c"},"source":["#start fine tuning\n","\n","# it is being trained on just an example data, for proper finetuning dataset must be large and carefully selected\n","!python3 DeepSpeech.py --train_cudnn true --n_hidden 2048 --dropout_rate 0.20 --epochs 100 --checkpoint_dir new_checkpoints --train_batch_size 8 --learning_rate 0.0001 --train_files training_data/train.csv --export_dir fine_tuned_model --dev_files training_data/val.csv --test_files training_data/test.csv"],"execution_count":21,"outputs":[{"output_type":"stream","text":["swig/python detected a memory leak of type 'Alphabet *', no destructor found.\n","I Loading best validating checkpoint from new_checkpoints/best_dev-732522\n","I Loading variable from checkpoint: beta1_power\n","I Loading variable from checkpoint: beta2_power\n","I Loading variable from checkpoint: cudnn_lstm/opaque_kernel\n","I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam\n","I Loading variable from checkpoint: cudnn_lstm/opaque_kernel/Adam_1\n","I Loading variable from checkpoint: global_step\n","I Loading variable from checkpoint: layer_1/bias\n","I Loading variable from checkpoint: layer_1/bias/Adam\n","I Loading variable from checkpoint: layer_1/bias/Adam_1\n","I Loading variable from checkpoint: layer_1/weights\n","I Loading variable from checkpoint: layer_1/weights/Adam\n","I Loading variable from checkpoint: layer_1/weights/Adam_1\n","I Loading variable from checkpoint: layer_2/bias\n","I Loading variable from checkpoint: layer_2/bias/Adam\n","I Loading variable from checkpoint: layer_2/bias/Adam_1\n","I Loading variable from checkpoint: layer_2/weights\n","I Loading variable from checkpoint: layer_2/weights/Adam\n","I Loading variable from checkpoint: layer_2/weights/Adam_1\n","I Loading variable from checkpoint: layer_3/bias\n","I Loading variable from checkpoint: layer_3/bias/Adam\n","I Loading variable from checkpoint: layer_3/bias/Adam_1\n","I Loading variable from checkpoint: layer_3/weights\n","I Loading variable from checkpoint: layer_3/weights/Adam\n","I Loading variable from checkpoint: layer_3/weights/Adam_1\n","I Loading variable from checkpoint: layer_5/bias\n","I Loading variable from checkpoint: layer_5/bias/Adam\n","I Loading variable from checkpoint: layer_5/bias/Adam_1\n","I Loading variable from checkpoint: layer_5/weights\n","I Loading variable from checkpoint: layer_5/weights/Adam\n","I Loading variable from checkpoint: layer_5/weights/Adam_1\n","I Loading variable from checkpoint: layer_6/bias\n","I Loading variable from checkpoint: layer_6/bias/Adam\n","I Loading variable from checkpoint: layer_6/bias/Adam_1\n","I Loading variable from checkpoint: layer_6/weights\n","I Loading variable from checkpoint: layer_6/weights/Adam\n","I Loading variable from checkpoint: layer_6/weights/Adam_1\n","I Initializing variable: learning_rate\n","I STARTING Optimization\n","Epoch 0 |   Training | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 128.169510      \n","Epoch 0 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 73.338579 | Dataset: training_data/val.csv\n","I Saved new best validating model with loss 73.338579 to: new_checkpoints/best_dev-732523\n","Epoch 1 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 84.108681       \n","Epoch 1 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 62.266779 | Dataset: training_data/val.csv\n","I Saved new best validating model with loss 62.266779 to: new_checkpoints/best_dev-732524\n","Epoch 2 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 63.164181       \n","Epoch 2 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 61.643448 | Dataset: training_data/val.csv\n","I Saved new best validating model with loss 61.643448 to: new_checkpoints/best_dev-732525\n","Epoch 3 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 49.154442       \n","Epoch 3 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 61.725931 | Dataset: training_data/val.csv\n","Epoch 4 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 37.585114       \n","Epoch 4 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 61.339016 | Dataset: training_data/val.csv\n","I Saved new best validating model with loss 61.339016 to: new_checkpoints/best_dev-732527\n","Epoch 5 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 34.262283       \n","Epoch 5 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 61.996616 | Dataset: training_data/val.csv\n","Epoch 6 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 28.307369       \n","Epoch 6 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 61.952610 | Dataset: training_data/val.csv\n","Epoch 7 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 22.910980       \n","Epoch 7 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 62.322149 | Dataset: training_data/val.csv\n","Epoch 8 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 18.595671       \n","Epoch 8 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 63.904692 | Dataset: training_data/val.csv\n","Epoch 9 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 13.843060       \n","Epoch 9 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 66.326868 | Dataset: training_data/val.csv\n","Epoch 10 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 12.076617      \n","Epoch 10 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 69.081993 | Dataset: training_data/val.csv\n","Epoch 11 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 9.292593       \n","Epoch 11 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 72.448223 | Dataset: training_data/val.csv\n","Epoch 12 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 7.273459       \n","Epoch 12 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 76.980385 | Dataset: training_data/val.csv\n","Epoch 13 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 5.810446       \n","Epoch 13 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 81.003899 | Dataset: training_data/val.csv\n","Epoch 14 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 4.934145       \n","Epoch 14 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 84.752365 | Dataset: training_data/val.csv\n","Epoch 15 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 3.890448       \n","Epoch 15 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 88.142265 | Dataset: training_data/val.csv\n","Epoch 16 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 3.381002       \n","Epoch 16 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 91.171745 | Dataset: training_data/val.csv\n","Epoch 17 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 2.849390       \n","Epoch 17 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 94.727356 | Dataset: training_data/val.csv\n","Epoch 18 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 2.516209       \n","Epoch 18 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 97.154770 | Dataset: training_data/val.csv\n","Epoch 19 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 1.936731       \n","Epoch 19 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 99.632042 | Dataset: training_data/val.csv\n","Epoch 20 |   Training | Elapsed Time: 0:00:01 | Steps: 1 | Loss: 1.727194       \n","Epoch 20 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 101.781143 | Dataset: training_data/val.csv\n","Epoch 21 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 1.419250       \n","Epoch 21 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 104.470413 | Dataset: training_data/val.csv\n","Epoch 22 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 1.797024       \n","Epoch 22 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 104.984795 | Dataset: training_data/val.csv\n","Epoch 23 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 1.142335       \n","Epoch 23 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 106.162354 | Dataset: training_data/val.csv\n","Epoch 24 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 1.057618       \n","Epoch 24 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 106.706905 | Dataset: training_data/val.csv\n","Epoch 25 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.923940       \n","Epoch 25 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 107.272110 | Dataset: training_data/val.csv\n","Epoch 26 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.748113       \n","Epoch 26 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 110.881222 | Dataset: training_data/val.csv\n","Epoch 27 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.936855       \n","Epoch 27 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 114.682510 | Dataset: training_data/val.csv\n","Epoch 28 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.852045       \n","Epoch 28 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 116.075214 | Dataset: training_data/val.csv\n","Epoch 29 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.514894       \n","Epoch 29 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 118.987011 | Dataset: training_data/val.csv\n","Epoch 30 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.573992       \n","Epoch 30 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 121.393936 | Dataset: training_data/val.csv\n","Epoch 31 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.490415       \n","Epoch 31 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 122.747803 | Dataset: training_data/val.csv\n","Epoch 32 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.483076       \n","Epoch 32 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 124.323704 | Dataset: training_data/val.csv\n","Epoch 33 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.518263       \n","Epoch 33 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 125.614952 | Dataset: training_data/val.csv\n","Epoch 34 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.371581       \n","Epoch 34 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 126.245586 | Dataset: training_data/val.csv\n","Epoch 35 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.371629       \n","Epoch 35 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 126.857754 | Dataset: training_data/val.csv\n","Epoch 36 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.326101       \n","Epoch 36 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 127.605366 | Dataset: training_data/val.csv\n","Epoch 37 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.319277       \n","Epoch 37 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 128.099640 | Dataset: training_data/val.csv\n","Epoch 38 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.321058       \n","Epoch 38 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 128.664822 | Dataset: training_data/val.csv\n","Epoch 39 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.283141       \n","Epoch 39 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 129.704002 | Dataset: training_data/val.csv\n","Epoch 40 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.246751       \n","Epoch 40 | Validation | Elapsed Time: 0:00:02 | Steps: 2 | Loss: 130.781429 | Dataset: training_data/val.csv\n","Epoch 41 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.241479       \n","Epoch 41 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 131.639908 | Dataset: training_data/val.csv\n","Epoch 42 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.201904       \n","Epoch 42 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 132.307167 | Dataset: training_data/val.csv\n","Epoch 43 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.203120       \n","Epoch 43 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 132.793652 | Dataset: training_data/val.csv\n","Epoch 44 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.185611       \n","Epoch 44 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.482128 | Dataset: training_data/val.csv\n","Epoch 45 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.172484       \n","Epoch 45 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.497017 | Dataset: training_data/val.csv\n","Epoch 46 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.147043       \n","Epoch 46 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 135.359596 | Dataset: training_data/val.csv\n","Epoch 47 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.135913       \n","Epoch 47 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 135.996853 | Dataset: training_data/val.csv\n","Epoch 48 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.126141       \n","Epoch 48 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 136.542904 | Dataset: training_data/val.csv\n","Epoch 49 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.157151       \n","Epoch 49 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 137.077179 | Dataset: training_data/val.csv\n","Epoch 50 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.123406       \n","Epoch 50 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 137.584099 | Dataset: training_data/val.csv\n","Epoch 51 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.120601       \n","Epoch 51 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 138.073524 | Dataset: training_data/val.csv\n","Epoch 52 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.111869       \n","Epoch 52 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 138.549137 | Dataset: training_data/val.csv\n","Epoch 53 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.098805       \n","Epoch 53 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 138.980534 | Dataset: training_data/val.csv\n","Epoch 54 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.076024       \n","Epoch 54 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 139.248695 | Dataset: training_data/val.csv\n","Epoch 55 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.079944       \n","Epoch 55 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 139.526886 | Dataset: training_data/val.csv\n","Epoch 56 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.080005       \n","Epoch 56 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 139.811924 | Dataset: training_data/val.csv\n","Epoch 57 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.091066       \n","Epoch 57 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 140.079235 | Dataset: training_data/val.csv\n","Epoch 58 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.077362       \n","Epoch 58 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 140.334393 | Dataset: training_data/val.csv\n","Epoch 59 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.080485       \n","Epoch 59 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 140.587681 | Dataset: training_data/val.csv\n","Epoch 60 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.073238       \n","Epoch 60 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 140.827164 | Dataset: training_data/val.csv\n","Epoch 61 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.045812       \n","Epoch 61 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 141.051132 | Dataset: training_data/val.csv\n","Epoch 62 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 1.171792       \n","Epoch 62 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 146.801399 | Dataset: training_data/val.csv\n","Epoch 63 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.064693       \n","Epoch 63 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 149.420368 | Dataset: training_data/val.csv\n","Epoch 64 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.131527       \n","Epoch 64 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 156.322613 | Dataset: training_data/val.csv\n","Epoch 65 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.413655       \n","Epoch 65 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 161.699665 | Dataset: training_data/val.csv\n","Epoch 66 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 2.128216       \n","Epoch 66 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 163.694946 | Dataset: training_data/val.csv\n","Epoch 67 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 2.590345       \n","Epoch 67 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 165.143196 | Dataset: training_data/val.csv\n","Epoch 68 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.815741       \n","Epoch 68 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 163.704060 | Dataset: training_data/val.csv\n","Epoch 69 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.986797       \n","Epoch 69 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 160.485786 | Dataset: training_data/val.csv\n","Epoch 70 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 2.037382       \n","Epoch 70 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 156.586159 | Dataset: training_data/val.csv\n","Epoch 71 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.311263       \n","Epoch 71 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 154.057182 | Dataset: training_data/val.csv\n","Epoch 72 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.254228       \n","Epoch 72 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 151.077641 | Dataset: training_data/val.csv\n","Epoch 73 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.738396       \n","Epoch 73 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 148.256126 | Dataset: training_data/val.csv\n","Epoch 74 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.309218       \n","Epoch 74 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 145.065224 | Dataset: training_data/val.csv\n","Epoch 75 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.342884       \n","Epoch 75 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 142.759521 | Dataset: training_data/val.csv\n","Epoch 76 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.291202       \n","Epoch 76 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 142.498291 | Dataset: training_data/val.csv\n","Epoch 77 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.214166       \n","Epoch 77 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 140.719814 | Dataset: training_data/val.csv\n","Epoch 78 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.191344       \n","Epoch 78 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 138.540714 | Dataset: training_data/val.csv\n","Epoch 79 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.326254       \n","Epoch 79 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 137.578671 | Dataset: training_data/val.csv\n","Epoch 80 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.267687       \n","Epoch 80 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 137.084442 | Dataset: training_data/val.csv\n","Epoch 81 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.195881       \n","Epoch 81 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 135.549320 | Dataset: training_data/val.csv\n","Epoch 82 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.239375       \n","Epoch 82 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 135.509521 | Dataset: training_data/val.csv\n","Epoch 83 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.201138       \n","Epoch 83 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 135.265148 | Dataset: training_data/val.csv\n","Epoch 84 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.302089       \n","Epoch 84 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.943176 | Dataset: training_data/val.csv\n","Epoch 85 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.161710       \n","Epoch 85 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.710632 | Dataset: training_data/val.csv\n","Epoch 86 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.150965       \n","Epoch 86 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.521713 | Dataset: training_data/val.csv\n","Epoch 87 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.190565       \n","Epoch 87 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.351208 | Dataset: training_data/val.csv\n","Epoch 88 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.117690       \n","Epoch 88 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.095657 | Dataset: training_data/val.csv\n","Epoch 89 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.139817       \n","Epoch 89 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.990864 | Dataset: training_data/val.csv\n","Epoch 90 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.096533       \n","Epoch 90 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.971256 | Dataset: training_data/val.csv\n","Epoch 91 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.100044       \n","Epoch 91 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.788185 | Dataset: training_data/val.csv\n","Epoch 92 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.103831       \n","Epoch 92 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.740173 | Dataset: training_data/val.csv\n","Epoch 93 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.127753       \n","Epoch 93 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.733803 | Dataset: training_data/val.csv\n","Epoch 94 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.184277       \n","Epoch 94 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 133.918407 | Dataset: training_data/val.csv\n","Epoch 95 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.071476       \n","Epoch 95 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.129963 | Dataset: training_data/val.csv\n","Epoch 96 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.065616       \n","Epoch 96 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.405602 | Dataset: training_data/val.csv\n","Epoch 97 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.285314       \n","Epoch 97 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.518272 | Dataset: training_data/val.csv\n","Epoch 98 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.113230       \n","Epoch 98 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.681992 | Dataset: training_data/val.csv\n","Epoch 99 |   Training | Elapsed Time: 0:00:00 | Steps: 1 | Loss: 0.077669       \n","Epoch 99 | Validation | Elapsed Time: 0:00:00 | Steps: 2 | Loss: 134.833706 | Dataset: training_data/val.csv\n","I FINISHED optimization in 0:29:51.285538\n","swig/python detected a memory leak of type 'Alphabet *', no destructor found.\n","I Loading best validating checkpoint from new_checkpoints/best_dev-732527\n","I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n","I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n","I Loading variable from checkpoint: global_step\n","I Loading variable from checkpoint: layer_1/bias\n","I Loading variable from checkpoint: layer_1/weights\n","I Loading variable from checkpoint: layer_2/bias\n","I Loading variable from checkpoint: layer_2/weights\n","I Loading variable from checkpoint: layer_3/bias\n","I Loading variable from checkpoint: layer_3/weights\n","I Loading variable from checkpoint: layer_5/bias\n","I Loading variable from checkpoint: layer_5/weights\n","I Loading variable from checkpoint: layer_6/bias\n","I Loading variable from checkpoint: layer_6/weights\n","Testing model on training_data/test.csv\n","Test epoch | Steps: 0 | Elapsed Time: 0:00:00                                   swig/python detected a memory leak of type 'Output *', no destructor found.\n","swig/python detected a memory leak of type 'std::vector< Output,std::allocator< Output > > *', no destructor found.\n","swig/python detected a memory leak of type 'std::vector< std::vector< Output,std::allocator< Output > > > *', no destructor found.\n","swig/python detected a memory leak of type 'Alphabet *', no destructor found.\n","Test epoch | Steps: 1 | Elapsed Time: 0:00:08                                   swig/python detected a memory leak of type 'Output *', no destructor found.\n","swig/python detected a memory leak of type 'std::vector< Output,std::allocator< Output > > *', no destructor found.\n","swig/python detected a memory leak of type 'std::vector< std::vector< Output,std::allocator< Output > > > *', no destructor found.\n","swig/python detected a memory leak of type 'Alphabet *', no destructor found.\n","Test epoch | Steps: 2 | Elapsed Time: 0:00:10                                   \n","Test on training_data/test.csv - WER: 0.360000, CER: 0.212329, loss: 61.339024\n","--------------------------------------------------------------------------------\n","Best WER: \n","--------------------------------------------------------------------------------\n","WER: 0.333333, CER: 0.175676, loss: 47.543678\n"," - wav: file://training_data/audio_chunks/183.wav\n"," - src: \" course data scientist the median base salaries of the data scientists can\"\n"," - res: \"course data scientist the median barriers of the data scientist to\"\n","--------------------------------------------------------------------------------\n","WER: 0.384615, CER: 0.250000, loss: 75.134369\n"," - wav: file://training_data/audio_chunks/177.wav\n"," - src: \" leading to cost efficiency with data science it is possible to not only\"\n"," - res: \"leading to posterity what data science it is possible to note\"\n","--------------------------------------------------------------------------------\n","Median WER: \n","--------------------------------------------------------------------------------\n","WER: 0.384615, CER: 0.250000, loss: 75.134369\n"," - wav: file://training_data/audio_chunks/177.wav\n"," - src: \" leading to cost efficiency with data science it is possible to not only\"\n"," - res: \"leading to posterity what data science it is possible to note\"\n","--------------------------------------------------------------------------------\n","Worst WER: \n","--------------------------------------------------------------------------------\n","WER: 0.333333, CER: 0.175676, loss: 47.543678\n"," - wav: file://training_data/audio_chunks/183.wav\n"," - src: \" course data scientist the median base salaries of the data scientists can\"\n"," - res: \"course data scientist the median barriers of the data scientist to\"\n","--------------------------------------------------------------------------------\n","WER: 0.384615, CER: 0.250000, loss: 75.134369\n"," - wav: file://training_data/audio_chunks/177.wav\n"," - src: \" leading to cost efficiency with data science it is possible to not only\"\n"," - res: \"leading to posterity what data science it is possible to note\"\n","--------------------------------------------------------------------------------\n","I Exporting the model...\n","I Loading best validating checkpoint from new_checkpoints/best_dev-732527\n","I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/bias\n","I Loading variable from checkpoint: cudnn_lstm/rnn/multi_rnn_cell/cell_0/cudnn_compatible_lstm_cell/kernel\n","I Loading variable from checkpoint: layer_1/bias\n","I Loading variable from checkpoint: layer_1/weights\n","I Loading variable from checkpoint: layer_2/bias\n","I Loading variable from checkpoint: layer_2/weights\n","I Loading variable from checkpoint: layer_3/bias\n","I Loading variable from checkpoint: layer_3/weights\n","I Loading variable from checkpoint: layer_5/bias\n","I Loading variable from checkpoint: layer_5/weights\n","I Loading variable from checkpoint: layer_6/bias\n","I Loading variable from checkpoint: layer_6/weights\n","I Models exported at fine_tuned_model\n","I Model metadata file saved to fine_tuned_model/author_model_0.0.1.md. Before submitting the exported model for publishing make sure all information in the metadata file is correct, and complete the URL fields.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"u11vFEJLkCyD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1593348908575,"user_tz":-300,"elapsed":8410,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"ed7ff229-6402-45ee-82f3-d9b75a4c1fce"},"source":["# convert pb outmut to memory mappable pbmm\n","!python3 util/taskcluster.py --source tensorflow --artifact convert_graphdef_memmapped_format --branch r1.15 --target .\n","!./convert_graphdef_memmapped_format --in_graph=fine_tuned_model/output_graph.pb --out_graph=fine_tuned_model/output_graph.pbmm\n"],"execution_count":22,"outputs":[{"output_type":"stream","text":["File already exists: /content/deepspeech/convert_graphdef_memmapped_format\n","2020-06-28 12:55:06.609378: I tensorflow/contrib/util/convert_graphdef_memmapped_format_lib.cc:171] Converted 7 nodes\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a3cG3cjDkEz_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":697},"executionInfo":{"status":"ok","timestamp":1593348985407,"user_tz":-300,"elapsed":25080,"user":{"displayName":"Raja Asim","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjWWAM2a1zPM1lcj0bcWwfQYRuJYDumRJSSZ1-cug=s64","userId":"08441109681798812112"}},"outputId":"45384586-c783-43ca-cb1d-5be2ba225e3f"},"source":["# test the model\n","%cd ..\n","from deepspeech import Model\n","import scipy.io.wavfile as wav\n","import pandas as pd\n","import pandas as pd\n","\n","dsModel = Model(\"deepspeech/fine_tuned_model/output_graph.pbmm\")  # make deepspeech model from new finetuned model\n","\n","import os\n","df=pd.read_csv('sample_data.csv')  # read the csv file\n","for i,row in df.iterrows():\n","  # resample the input file to 16KHz\n","  command=\"ffmpeg -i \"+row['File_Path'] +\"-ar 16000 -acodec pcm_s16le -ac 1 \"+row['File_Path']\n","  os.system(command)\n","  fs, audio = wav.read(row['File_Path'])  # do inference with deepspeech\n","  output = dsModel.stt(audio)\n","  print(\"Deepspeech Transcription: \", output)\n","  print(\"Actual Transcription: \", row['Transcription'])\n","  print(\"-----------------------------------------------------------------------------------\")"],"execution_count":24,"outputs":[{"output_type":"stream","text":["/content\n","Deepspeech Transcription:  anderstanding of genetic issues in reaction to particular drugete\n","Actual Transcription:   understanding of genetic issues in reaction to particular drugs and\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  andticeases lagistic companies like dhl fedex have discovered the best routes to\n","Actual Transcription:   diseases logistic companies like DHL FedEx have discovered the best routes to\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  ship the best suted time to deliver the best mode of transport to choose tht\n","Actual Transcription:   ship the best suited time to deliver the best mode of transport to choose thus\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  leading to cros tof shenci wa data science it is popsible to notet\n","Actual Transcription:   leading to cost efficiency with data science it is possible to not only\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  predict employe attrition but to also understand key raria rosht sta ne\n","Actual Transcription:   predict employee attrition but to also understand key variables that influence\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  s employe turnover olso the airline companies can now easily predict figt\n","Actual Transcription:   employee turnover also the airline companies can now easily predict flight\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  e and no dified the passengers beforehand to inhance their traveli expadience well\n","Actual Transcription:   and notify the passengers beforehand to enhance their travel experience well if\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:    wondering there are various rules offered to a data scientist like the\n","Actual Transcription:   you're wondering there are various rules offered to a data scientist like data\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  anist machine learning engineer deep learning engilinio data engineer and o\n","Actual Transcription:   analyst machine learning engineer deep learning Ingenio data engineer and of\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  course data scientist the median boay sarries of a data scientist to\n","Actual Transcription:   course data scientist the median base salaries of the data scientists can\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:  range from inety five thousand dollars two one sixty five thousand dollars su bap wash aboutto\n","Actual Transcription:   range from ninety-five thousand dollars to one hundred and sixty-five thousand dollars so that was about the\n","-----------------------------------------------------------------------------------\n","Deepspeech Transcription:   a science are you ready to be a data scientist if yes then start to dayteo\n","Actual Transcription:   data science are you ready to be a data scientist if yes then start today the\n","-----------------------------------------------------------------------------------\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"dpnIzsP4-w_U","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UXftdafckE2H","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":129},"executionInfo":{"status":"ok","timestamp":1593341997003,"user_tz":-300,"elapsed":26560,"user":{"displayName":"Raja Asim","photoUrl":"","userId":"17826990570129583802"}},"outputId":"b1c75aa6-2550-47e4-b904-923c01b3afc6"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\", force_remount=True)\n","\n","!cp fine_tuned_model/output_graph.pbmm '/content/drive/My Drive'  # copy the model to your own drive to download"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1zmUKWpVb86l","colab_type":"text"},"source":["\n","\n","\n","\n","---\n","\n"]}]}